\subsection{Проблемы, возникающие в задачах оптимизации}
Обозначим трудности, проявляющиеся в ходе решения различных
экстремальных задач.

\subsubsection{Явление овражности}
\label{sec:problems-ill}

Большое число различных методов минимизации тем или иным образом
используют тот факт, что антиградиент функции $-f'(x)$ указывает на
направление её наискорейшего убывания.

Метод простого градиентного спуска\footnote{\gd{} более подробно
  рассмотрен далее, см. раздел \ref{sec:gd}.} (\gd{}) реализует эту
идею самым простым образом, а именно: поиск минимума функции
осуществляется путём последовательного продвижения вдоль её
антиградиента. На рисунке \ref{fig:gd-works} демонстрируется, как
\gd{}, начиная движение из точки $(0, 0)$, находит локальный минимум
функции\footnote{В качестве целевой здесь взята так называемая
  функция Химмельблау, которая рассматривается в
  разделе \ref{sec:himmelblau}.} в точке $(3,2)$.

\begin{figure}[!thb]
  \centering
  \begin{tikzpicture}
    \begin{axis}[x=.5cm,y=.5cm,ymin=-4,ymax=4]
      \input{himmelblau-contours.tkz.tex}
      \input{himmelblau_sgd_0.0,0.0_20_0.01-trace.tkz.tex}

      \node[circle,fill=black,scale=0.25,label={right:\contour{white}{$(3,2)$}}]
      at (axis cs:3,2) {};
    \end{axis}
  \end{tikzpicture}
  \caption{Процесс поиска минимума функции}
  \label{fig:gd-works}
\end{figure}

Тем не менее, на практике нередки случаи, когда следование направлению
$-f'(x)$ почти никак не позволяет приблизиться к минимуму целевой
функции.

\begin{wrapfigure}{r}{4cm}
  \vspace{-11pt}
  \begin{tikzpicture}
    \begin{axis}
      [x=1cm,y=6cm,
      yticklabel pos=right]
      \input{gully-contours.tkz.tex}
      \input{gully_sgd_0.5,3_30_0.0000099-trace.tkz.tex}
    \end{axis}
  \end{tikzpicture}
  \caption[Овражная функция]{Зацикливание \gd{} на овражной функции}
  \label{fig:gd-stalls}
\end{wrapfigure}

Подобная ситуация изображена на рисунке \ref{fig:gd-stalls}. Линии
уровня целевой функции сильно вытянуты, так что последовательные шаги
метода \gd{} постоянно оказываются то по одну, то по другую сторону
получившегося «оврага», а процесс поиска минимума сильно замедляется.

В таком случае говорят об \neword{овражности} или \neword{плохой
  обусловленности} целевой функции. Не случайной будет аналогия с
понятием плохо обусловленной матрицы. Связь терминов раскрывается в
следующем определении, которое вводит численную характеристику
овражности функции.

\begin{dfn}
  \label{dfn:gully}
  \neword{Степень овражности} выпуклой функции $f(x)$ есть отношение
  \begin{equation*}
    \eta = \frac{\lambda_{\max}}{\lambda_{\min}}
  \end{equation*}
  где $\lambda_{\max}, \lambda_{\min}$ — максимальное и минимальное
  собственное значение матрицы Гессе этой функции, соответственно.
\end{dfn}

Овражная функция имеет $\eta \gg 1$.

Степень овражности, грубо говоря, характеризует разброс собственных
значений матрицы Гессе.

Как будет показано в разделе \ref{sec:relax}, спектр гессиана целевой
функции имеет весьма большое значение при анализе областей
применимости различных методов оптимизации.

Более строгое определение понятия овражности дано в
\cite{chernorutsky04}.

\subsubsection{Явление многоэкстремальности}
\label{sec:problems-multiextr}

Функции, имеющие несколько локальных минимумов, называют
\neword{многоэкстремальными}. Такова, например, функция с
рисунка \ref{fig:gd-works}, обладающая по крайней мере четырьмя
минимумами. При этом функция может иметь не просто несколько, но
бесконечно много локальных минимумов. Многокритериальность целевой
функции осложняет решение задач, требующих точного определения
\emph{глобального} минимума.

Простейшая стратегия борьбы с многокритериальностью заключается в
проведении в многократном процесса минимизации несколько раз при
варьировании начального приближения. Если при этом получаются разные
ответы, выбирают тот, в котором достигается минимальное значение
целевой функции.Такой подход, вообще говоря, не гарантирует
определение глобального минимума в отсутствие дополнительных
соображений о выпуклости функции.
