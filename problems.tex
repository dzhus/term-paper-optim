\subsection{Проблемы, возникающие в задачах оптимизации}
Обозначим трудности, проявляющиеся в ходе решения различных
экстремальных задач.

\subsubsection{Явление овражности}
\label{sec:problems-ill}

Большое число различных методов оптимизационных тем или иным образом
используют тот факт, что антиградиент функции $-f'(x)$ указывает на
направление её наискорейшего убывания.

Метод простого градиентного спуска\footnote{\gd{} более подробно
  рассмотрен далее, см. раздел \ref{sec:gd}} (\gd{}) реализует эту
идею самым простым образом, а именно: поиск минимума функции
осуществляется путём последовательного продвижения вдоль её
антиградиента. На рисунке \ref{fig:gd-works} демонстрируется, как
\gd{} находит локальный минимум функции\footnote{Целевой функцией
  здесь является так называемая функция Химмельблау, которая
  рассматривается в разделе \ref{sec:himmelblau}}, начиная движение из
точки $(0, 0)$.

\begin{figure}[!thb]
  \centering
  \begin{tikzpicture}
    \begin{axis}[x=.5cm,y=.5cm]
      \input{himmelblau-contours.tkz.tex}
      \input{himmelblau_sgd_0.0,0.0_20_0.01-trace.tkz.tex}
      
      \node[circle,fill=black,scale=0.5,label={above
        right:\contour{white}{$(3,2)$}}] at (axis cs:3,2) {};
    \end{axis}
  \end{tikzpicture}
  \caption{Процесс поиска минимума функции}
  \label{fig:gd-works}
\end{figure}

Тем не менее, на практике нередки случаи, когда следование направлению
$-f'(x)$ почти никак не позволяет приблизиться к минимуму целевой
функции.

Подобная ситуация изображена на рисунке \ref{fig:gd-stalls}. Линии
уровня целевой функции сильно вытянуты, так что последовательные шаги
метода \gd{} постоянно оказываются то по одну, то по другую сторону
получившегося «оврага», а процесс поиска минимума сильно замедляется.

\begin{wrapfigure}{r}{4cm}
  \centering
  \begin{tikzpicture}
    \begin{axis}
      [x=1cm,y=6cm,
      yticklabel pos=right]
      \input{gully-contours.tkz.tex}
      \input{gully_sgd_0.5,3_30_0.0000099-trace.tkz.tex}
    \end{axis}
  \end{tikzpicture}
  \caption[Овражная функция]{Зацикливание \gd{} на овражной функции}
  \label{fig:gd-works}
\end{wrapfigure}

В таком случае говорят об \neword{овражности} или \neword{плохой
  обусловленности} целевой функции. Не случайной будет аналогия с
понятием плохо обусловленной матрицы. Связь терминов раскрывается в
следующем определении, которое вводит численную характеристику
овражности функции.

\begin{dfn}
  \label{dfn:ill-cond}
  \neword{Степенью овражности} выпуклой функции $f(x)$ называют
  отношение
  \begin{equation*}
    \eta = \frac{\lambda_{\max}}{\lambda_{\min}}
  \end{equation*}
  где $\lambda_{\max}, \lambda_{\min}$ — максимальное и минимальное
  собственное значение матрицы Гессе этой функции, соответственно.
\end{dfn}

Овражная функция имеет $\eta \gg 1$.

Степень овражности, грубо говоря, характеризует разброс собственных
значений матрицы Гессе. 

Как будет показано в разделе \ref{sec:relax}, спектр гессиана целевой
функции имеет весьма большое значение при анализе областей
применимости различных методов оптимизации.

Более строго определение понятия овражности дано в
\cite{chernorutsky04}.

\subsubsection{Явление многоэкстремальности}

Функции, имеющие несколько локальных минимумов, называют
\neword{многоэкстремальными}. Такова, например, функция с рисунка
\ref{fig:gd-works}, обладающая по крайней мере четырьмя минимумами.
При этом функция может иметь не просто несколько, но бесконечно много
локальных минимумов. Многокритериальность целевой функции осложняет
решение задач, требующих точного определения \emph{глобального}
минимума.

Простейшая стратегия борьбы с многокритериальностью заключается в
проведении в многократном процесса минимизации несколько раз при
варьировании начального приближения. Если при этом получаются разные
ответы, выбирают тот, в котором достигается минимальное значение
целевой функции.Такой подход, вообще говоря, не гарантирует
определение глобального минимума в отсутствие дополнительных
соображений о выпуклости функции.
