\subsection{Метод штрафных функций}
\label{sec:penalty}

\subsubsection{Общие сведения}

Методы, построенные на применении штрафных функций, позволяют решать
задачи на поиск минимума при наличии ограничений \emph{численно}.

Общая схема таких методов заключается в замене задачи условной
минимизации в некоторой области $D$, заданной ограничениями типа
неравенств
\begin{equation}
  \label{eq:penalty-problem-form-initial}
  \begin{cases}
    f(x) \to \min \\
    g_j(x) \leq 0,\, j=\overline{1,m} \\
    x \in \set{R}^n
  \end{cases}
\end{equation}
на задачу безусловной минимизации
\begin{equation}
  \label{eq:penalty-problem-form}
  P(x, r) = f(x) + \phi(x, p) \to \min
\end{equation}
где \neword{штраф} $\phi(x, p)$ удовлетворяет свойству
\begin{align*}
  \phi(x, p) = 0 &\quad x \in D\\
  \phi(x, p) \gg 0 &\quad x \notin D
\end{align*}
Таким образом, штрафная часть значительно возрастает при выходе за
пределы допустимого множества $D$.

Метод штрафных функций позволяет сводить задачи оптимизации при
наличии ограничений к задачам безусловной оптимизации, снижая таким
образом структурную сложность решаемой задачи.

Один из подходов к использованию штрафных функций заключается в
последовательном решении задач вида \ref{eq:penalty-problem-form},
параметризованных номером итерации $k$:
\begin{equation}
  \label{eq:penalty-iter}
  P_k(x, r) = f(x) + \phi(x, p_k) \to \min
\end{equation}
где функция $\phi(x, p_k)$ масштабируется на каждой итерации в сторону
увеличения или уменьшения.

\subsubsection{Метод внешних штрафных функций}

Методами внешних штрафных функций называют методы, использующие схему
\eqref{eq:penalty-iter} таким образом, что $\phi(x, p_k)$ с каждой
итерацией увеличивается, и положения вне допустимой области с ростом
$k$ становятся всё менее «выгодными». При этом начальное приближение
$x^1$ к точке минимума выбирается \emph{вне} $D$. Благодаря этому
приближение постепенно «скатывается» в область допустимых значений.

Один из таких методов, изложенный в \cite{himmelblau75} и
\cite{gill81}, предусматривает построение штрафной функции для задачи
\eqref{eq:cond-optim-problem-form} в виде:
\begin{equation}
  \label{eq:weisman}
  \phi(x, p_k) = p_k \sum_{j=1}^m{ \left [ g_j^+(x) \right ]^2}
\end{equation}
где $g_j^+(x) = \max\{0, g_j(x)\}$, так что штрафная часть отлична от
нуля и возрастает вне границ, заданных ограничениями $g_j(x)$, а
$\lim\limits_{k\to\infty}{p_k} = +\infty$.

В качестве критерия останова процесса \eqref{eq:penalty-iter} можно
выбрать условие
\begin{equation*}
  \phi(x^k, p_k) < \epsilon
\end{equation*}
где $x^k$ — приближение к точке минимума на $k$-ом шаге.

О сходимости метода внешних штрафных функций говорит следующая
теорема.
\begin{thm}
  \label{th:penalty-converge}
  Если $x^*$ — локальный минимум в задаче
  \eqref{eq:penalty-problem-form-initial}, то для достаточно больших
  $p_k$ существует такая зависимость $x^*(p_k)$, определяющая
  безусловный локальный минимум в задаче \eqref{eq:penalty-iter} при
  штрафе \eqref{eq:weisman}, что
  \begin{equation}
    \lim_{p_k \to +\infty}{x^*(p_k)} = x^*
  \end{equation}
\end{thm}

\begin{rem}
  \label{rem:penalty-convex-is-good}
  Теорема \eqref{th:penalty-converge}, вообще говоря, не гарантирует
  возможность определения \emph{глобального} минимума задачи
  \eqref{eq:penalty-problem-form-initial}.
\end{rem}

\subsubsection{Пример}
\label{sec:penalty-usage}

В разделе \ref{sec:kuhn-tucker} была решена задача условной
оптимизации \eqref{eq:cond-optim-problem}:
\begin{equation*}
  \begin{cases}
    f(x) = (x_1+4)^2 + (x_2-4)^2 \to \extr \\
    g_1(x) = 2x_1 - x_2 - 2 \leq 0 \\
    g_2(x) = -x_1 \leq 0 \\
    g_3(x) = -x_2 \leq 0
  \end{cases}
\end{equation*}
Среди условных экстремумов функции был найден минимум в точке \mbox{$A
  = (0, 4)$}. Найдём его с помощью штрафных функций.

\paragraph{Построение новой целевой функции}

Преобразуем задачу к виду \eqref{eq:penalty-iter}, выбирая штрафную
часть в виде \eqref{eq:weisman}:
\begin{equation}
  \label{eq:penalty-problem}
  P(x) = f(x) + p \sum_{j=1}^3{ \left [ g_j^+(x) \right ]^2} \to \min
\end{equation}

Отметим, что \eqref{eq:penalty-problem} строго
выпукла\footnote{Действительно, $\left[g_1(x)\right]^2=(2x_1-x_2-2)^2$
  выпукла в силу неотрицательной определённости своей матрицы Гессе
  $\left(\begin{smallmatrix}\phm{}8&-4\\-4&\phm{}2 \end{smallmatrix}\right)$,
  остальные слагаемые штрафа также очевидно выпуклы. Исходная функция
  строго выпукла (см. раздел \ref{sec:kuhn-tucker-solution},
  c. \pageref{eq:cond-optim-hess}), а потому в силу теоремы
  \ref{th:sconvex-f-sum} выпукла и вся функция
  \eqref{eq:penalty-problem}.}, поэтому теорема
\ref{th:penalty-converge} для неё выполняется и в смысле глобального
минимума в силу теоремы \ref{th:convex-f-smin}.

На рисунке \ref{fig:pen-contours} представлены линии уровня функции
$P(x)$ задачи \eqref{eq:penalty-problem} при различных значениях $p$
(при $p=0$ получается исходная функция $f(x)$ задачи
\eqref{eq:cond-optim-problem}). Видно, что с ростом $p$ влияние
штрафной части вне $D$ (\ref{plot:pen-boundaries}) значительно
возрастает, тогда как в допустимой области оптимизируемая функция не
претерпевает никаких изменений.

\input{penalty-plots.tex}

\paragraph{Использование \relch{}}

Для численного решения задачи \eqref{eq:penalty-problem} теперь уже
безусловной минимизации воспользуемся описанным ранее (см. раздел
\ref{sec:relch}) градиентным методом с чебышёвскими функциями
релаксации, выбирая в качестве начального приближения точку вне
области $D$.

Индекс $k$ в \eqref{eq:penalty-problem} опущен не случайно: опыт
показывает, что при достаточно большом начальном значении параметра
$p_0$ использование итерационного процесса \eqref{eq:penalty-iter}
может и не понадобиться, поскольку точка минимума $A$ с достаточной
точностью локализуется уже на первом шаге. Это проиллюстрировано на
рисунке \ref{fig:penalty}. Трассировка в таблице \ref{tab:penalty}
показывает, что положение точки безусловного минимума немного смещено
из $(0,4)$ в $(0.004, 4)$. Это объясняется тем, что сходимость метода
штрафных функций достигается при $p \to +\infty$. При использовании
подобного подхода стоит учитывать возможную высокую овражность
получающегося функционала.

\begin{figure}[p]
  \centering
  \begin{tikzpicture}
    \begin{axis}
      [xlabel=$x_1$, ylabel=$x_2$,
      ymax=6,
      x=0.7 cm, y=0.7 cm]
      \addplot[thick,draw=black] coordinates{(0,5)
        (0,0) (1,0) (3.5,5)};
      \input{penalty_supermax-contours.tkz.tex}

      \input{penalty_relch_-2,-1_20_200-trace.tkz.tex}
      \input{penalty_relch_2,-4_20_200-trace.tkz.tex}

      \node[circle,fill=black,scale=0.25,label={right:\contour{white}{$A$}}]
      at (axis cs:0,4) {};
    \end{axis}
  \end{tikzpicture}
  \caption[Метод штрафных функций]{Ход процесса решения задачи
    \eqref{eq:penalty-problem} с $p=10^5$ методом \relch{} с
    параметром $s=200$ в зависимости от выбора начальной точки}
  \label{fig:penalty}
\end{figure}

\begin{table}[p]
  \centering
  \pgfkeys{/pgfplots/table/font={\footnotesize}}
  \input{penalty_relch_2,-4_20_200-trace.tbl.tex}
  \caption{Минимизация функции \eqref{eq:penalty-problem} при $p=10^5$
    методом \relch{} с параметром $s=200$ при начальном приближении $(2,-4)$.}
  \label{tab:penalty}
\end{table}
